{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#imports to be able to pull data and prepare it for us\n",
    "import wrangle\n",
    "\n",
    "#imports for needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "import pydataset\n",
    "\n",
    "# ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#imports for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "    #import to be able to do decision tress\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "    #import to be able to do KNN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    #import to be able to do logistic regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    #import to be able to do random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.acquire_game_sales()\n",
    "df = wrangle.clean_game_sales(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16327 entries, 1 to 16600\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   Platform              16327 non-null  object  \n",
      " 1   Year                  16327 non-null  int64   \n",
      " 2   Genre                 16327 non-null  object  \n",
      " 3   Publisher             16327 non-null  object  \n",
      " 4   Global_Sales          16327 non-null  float64 \n",
      " 5   years_binned          16318 non-null  category\n",
      " 6   level_of_success      16327 non-null  category\n",
      " 7   Nintendo              16327 non-null  uint8   \n",
      " 8   Playstation           16327 non-null  uint8   \n",
      " 9   Xbox                  16327 non-null  uint8   \n",
      " 10  Computer              16327 non-null  uint8   \n",
      " 11  Sega                  16327 non-null  uint8   \n",
      " 12  Other                 16327 non-null  uint8   \n",
      " 13  Action_Adventure      16327 non-null  uint8   \n",
      " 14  Simulation            16327 non-null  uint8   \n",
      " 15  Sports                16327 non-null  uint8   \n",
      " 16  Misc                  16327 non-null  uint8   \n",
      " 17  Role_Playing          16327 non-null  uint8   \n",
      " 18  Shooter               16327 non-null  uint8   \n",
      " 19  Strategy              16327 non-null  uint8   \n",
      " 20  Moderate_Success      16327 non-null  uint8   \n",
      " 21  Fairly_Successful     16327 non-null  uint8   \n",
      " 22  Very_Successful       16327 non-null  uint8   \n",
      " 23  Extremely_Successful  16327 non-null  uint8   \n",
      "dtypes: category(2), float64(1), int64(1), object(3), uint8(17)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = wrangle.focused_game_sales(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = wrangle.split_game_sales(df)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = wrangle.split_train_validate_test(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, validate2, test2 = wrangle.split_focused_game_sales(df2)\n",
    "X_train2, X_validate2, X_test2, y_train2, y_validate2, y_test2 = wrangle.split_train_validate_test(train2, validate2, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_of_success    \n",
       "Fairly Successful       3600\n",
       "Moderate Success        3364\n",
       "Extremely Successful    1278\n",
       "Very Successful          900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (train.level_of_success == 'Fairly Successful').mean()\n",
    "round(baseline_accuracy, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Extremely Successful       0.00      0.00      0.00      1278\n",
      "   Fairly Successful       0.41      0.70      0.52      3600\n",
      "    Moderate Success       0.45      0.41      0.43      3364\n",
      "     Very Successful       0.00      0.00      0.00       900\n",
      "\n",
      "            accuracy                           0.43      9142\n",
      "           macro avg       0.22      0.28      0.24      9142\n",
      "        weighted avg       0.33      0.43      0.36      9142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train2, y_pred))\n",
    "# accuracy of .43 isnt great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are four ways to check if the predictions are right or wrong:\n",
    "1. TN / True Negative: \n",
    "    - the case was negative and predicted negative\n",
    "2. TP / True Positive: \n",
    "    - the case was positive and predicted positive\n",
    "3. FN / False Negative: \n",
    "    - the case was positive but predicted negative\n",
    "4. FP / False Positive: \n",
    "    - the case was negative but predicted positive\n",
    "- **Precision**\n",
    "    - what percent of my predictions wer correct?\n",
    "        - precision for Extremely Successful: 0\n",
    "        - precision for Fairly Successful: 0.41\n",
    "        - precision for Moderate Success: 0.45\n",
    "        - precision for Very Successful: 0\n",
    "- **Recall**\n",
    "    - what percent of the postive cases did I catch?\n",
    "        - recall for Extremely Successful: 0\n",
    "        - recall for Fairly Successful: 0.7\n",
    "        - recall for Moderate Success: 0.41\n",
    "        - recall for Very Successful: 0\n",
    "- **F1 score**\n",
    "    - what percent of positive predictions were correct?\n",
    "        - f1 score for Extremely Successful: 0\n",
    "        - f1 score for Fairly Successful: 0.52\n",
    "        - f1 score for Moderate Success: 0.43\n",
    "        - f1 score for Very Successful: 0\n",
    "    - what is the accuracy of the f1 score prediction?\n",
    "        - 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.39\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.43\n"
     ]
    }
   ],
   "source": [
    "logit1 = LogisticRegression(random_state=123)\n",
    "# Fit a model using only these specified features\n",
    "# logit.fit(X_train[[\"age\", \"pclass\", \"fare\"]], y_train)\n",
    "logit1.fit(X_train2, y_train2)\n",
    "\n",
    "# Since we .fit on a subset, we .predict on that same subset of features\n",
    "y_pred = logit1.predict(X_train2)\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train2, y_train2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on all features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.43\n"
     ]
    }
   ],
   "source": [
    "# All features, all default hyperparameters\n",
    "logit2 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = logit2.predict(X_train2)\n",
    "\n",
    "print(\"Model trained on all features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit2.score(X_train2, y_train2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit 3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.32\n"
     ]
    }
   ],
   "source": [
    "# All features, but we'll use the class_weights to hold the actual ratios`\n",
    "logit3 = LogisticRegression(random_state=123, class_weight='balanced')\n",
    "\n",
    "logit3.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = logit3.predict(X_train2)\n",
    "\n",
    "accuracy = logit3.score(X_train2, y_train2)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.32 while the previous 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Year\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Nintendo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.43\n"
     ]
    }
   ],
   "source": [
    "features = [\"Nintendo\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- This model has an accuracy the same as the first 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Playstation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Playstation\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Xbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Xbox\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Computer\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Sega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Sega\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Other\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Action_Adventure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.4\n"
     ]
    }
   ],
   "source": [
    "features = [\"Action_Adventure\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.4 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Simulation\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Sports\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Misc\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Role_Playing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Role_Playing\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Shooter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Shooter\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Only Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features and we're setting the class_weight hyperparameter\n",
      "Accuracy of Logistic Regression classifier on training set: 0.39\n"
     ]
    }
   ],
   "source": [
    "features = [\"Strategy\"]\n",
    "\n",
    "# All features, but we'll use the class_weights to hold the actual ratios\n",
    "logit4 = LogisticRegression(random_state=123)\n",
    "\n",
    "logit4.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit4.predict(X_train[features])\n",
    "\n",
    "accuracy = logit4.score(X_train[features], y_train)\n",
    "\n",
    "print(\"All Features and we're setting the class_weight hyperparameter\")\n",
    "print(f'Accuracy of Logistic Regression classifier on training set: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "- will not use this model because the accuracy is 0.39 while the first 2 were are 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best Model is For Linear Regression Models is Between Logit 1, and Logit 2\n",
    "## I will continue with logit 1\n",
    "- With a baseline of 0.394 and a model accuracy of 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree For the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = train2.drop(columns='level_of_success')\n",
    "y_train2 = train2.level_of_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf1.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fairly Successful       8243\n",
       "Moderate Success         772\n",
       "Extremely Successful     127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred).value_counts()\n",
    "# Fairly Successful is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4339313060599431"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model accuracy\n",
    "clf1.score(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  63, 1170,   45,    0],\n",
       "       [  40, 3387,  173,    0],\n",
       "       [   3, 2844,  517,    0],\n",
       "       [  21,  842,   37,    0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_train2, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely Successful': {'precision': 0.49606299212598426,\n",
       "  'recall': 0.04929577464788732,\n",
       "  'f1-score': 0.0896797153024911,\n",
       "  'support': 1278},\n",
       " 'Fairly Successful': {'precision': 0.4108940919568118,\n",
       "  'recall': 0.9408333333333333,\n",
       "  'f1-score': 0.5719834501393227,\n",
       "  'support': 3600},\n",
       " 'Moderate Success': {'precision': 0.6696891191709845,\n",
       "  'recall': 0.15368608799048752,\n",
       "  'f1-score': 0.25,\n",
       "  'support': 3364},\n",
       " 'Very Successful': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 900},\n",
       " 'accuracy': 0.4339313060599431,\n",
       " 'macro avg': {'precision': 0.39416155081344517,\n",
       "  'recall': 0.28595379899292706,\n",
       "  'f1-score': 0.22791579136045345,\n",
       "  'support': 9142},\n",
       " 'weighted avg': {'precision': 0.477578367082993,\n",
       "  'recall': 0.4339313060599431,\n",
       "  'f1-score': 0.32976931707046003,\n",
       "  'support': 9142}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Extremely Successful</th>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.049296</td>\n",
       "      <td>0.089680</td>\n",
       "      <td>1278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairly Successful</th>\n",
       "      <td>0.410894</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>0.571983</td>\n",
       "      <td>3600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moderate Success</th>\n",
       "      <td>0.669689</td>\n",
       "      <td>0.153686</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Successful</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.433931</td>\n",
       "      <td>0.433931</td>\n",
       "      <td>0.433931</td>\n",
       "      <td>0.433931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.394162</td>\n",
       "      <td>0.285954</td>\n",
       "      <td>0.227916</td>\n",
       "      <td>9142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.477578</td>\n",
       "      <td>0.433931</td>\n",
       "      <td>0.329769</td>\n",
       "      <td>9142.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      precision    recall  f1-score      support\n",
       "Extremely Successful   0.496063  0.049296  0.089680  1278.000000\n",
       "Fairly Successful      0.410894  0.940833  0.571983  3600.000000\n",
       "Moderate Success       0.669689  0.153686  0.250000  3364.000000\n",
       "Very Successful        0.000000  0.000000  0.000000   900.000000\n",
       "accuracy               0.433931  0.433931  0.433931     0.433931\n",
       "macro avg              0.394162  0.285954  0.227916  9142.000000\n",
       "weighted avg           0.477578  0.433931  0.329769  9142.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(class_report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for our model is: \n",
      " 0.4339\n",
      "The True Positive Rate is :\n",
      "  0.9408\n",
      "The False Positive Rate is :\n",
      "  0.9155\n",
      "The True Negative Rate is :\n",
      " 0.0493\n",
      "The False Negative Rate is :\n",
      " 0.0111\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf1.score(X_train2, y_train2)\n",
    "\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "\n",
    "print(f'The Accuracy for our model is: \\n', round(accuracy,4))\n",
    "print(f'The True Positive Rate is :\\n ',round(tpr,4))\n",
    "print(f'The False Positive Rate is :\\n ', round(fpr,4))\n",
    "print(f'The True Negative Rate is :\\n', round(tnr,4)) \n",
    "print(f'The False Negative Rate is :\\n', round(fnr,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.47\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "# Now let's train the model!\n",
    "knn.fit(X_train2, y_train2)\n",
    "# Let's check the accuracy\n",
    "accuracy = knn.score(X_train2, y_train2)\n",
    "print(f\"accuracy is {accuracy:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = knn.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Extremely Successful       0.31      0.33      0.32      1278\n",
      "   Fairly Successful       0.48      0.58      0.53      3600\n",
      "    Moderate Success       0.53      0.51      0.52      3364\n",
      "     Very Successful       0.26      0.04      0.07       900\n",
      "\n",
      "            accuracy                           0.47      9142\n",
      "           macro avg       0.40      0.37      0.36      9142\n",
      "        weighted avg       0.45      0.47      0.45      9142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our other classification metrics\n",
    "# y_train is the actual labels for the target variable\n",
    "# y_pred is the predictions that the model makes based off our X features\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Let's see how well this model performs on out of sample data!\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_validate2, y_validate2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Moderate Success', 'Moderate Success', 'Moderate Success',\n",
       "       'Extremely Successful'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the predictions from the model\n",
    "y_pred = knn.predict(X_validate2)\n",
    "y_pred[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_of_success</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14716</th>\n",
       "      <td>Moderate Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11930</th>\n",
       "      <td>Moderate Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15241</th>\n",
       "      <td>Moderate Success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>Extremely Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           level_of_success\n",
       "Rank                       \n",
       "14716      Moderate Success\n",
       "11930      Moderate Success\n",
       "15241      Moderate Success\n",
       "1400   Extremely Successful"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Extremely Successful       0.26      0.29      0.27       534\n",
      "   Fairly Successful       0.43      0.53      0.47      1509\n",
      "    Moderate Success       0.48      0.46      0.47      1471\n",
      "     Very Successful       0.17      0.02      0.04       405\n",
      "\n",
      "            accuracy                           0.42      3919\n",
      "           macro avg       0.33      0.32      0.31      3919\n",
      "        weighted avg       0.40      0.42      0.40      3919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check our other classification metrics\n",
    "print(classification_report(y_validate2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Accuracies Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit 1 Model on Train: \n",
      " 0.4266\n",
      "Accuracy of Decision Tree Model on Train: \n",
      " 0.4339\n",
      "Accuracy of KNN Model on Train: \n",
      " 0.4696\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logit 1 Model on Train: \\n', round(logit1.score(X_train2, y_train2),4))\n",
    "print('Accuracy of Decision Tree Model on Train: \\n', round(clf1.score(X_train2, y_train2),4))\n",
    "print('Accuracy of KNN Model on Train: \\n',round(knn.score(X_train2, y_train2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit 1 Model on Validate: \n",
      " 0.4271\n",
      "Accuracy of Decision Tree Model on Validate: \n",
      " 0.4269\n",
      "Accuracy of KNN Model on Validate: \n",
      " 0.4167\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logit 1 Model on Validate: \\n', round(logit1.score(X_validate2, y_validate2),4))\n",
    "print('Accuracy of Decision Tree Model on Validate: \\n', round(clf1.score(X_validate2, y_validate2),4))\n",
    "print('Accuracy of KNN Model on Validate: \\n',round(knn.score(X_validate2, y_validate2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit 1 Model on Test: \n",
      " 0.4235\n",
      "Accuracy of Decision Tree Model on Test: \n",
      " 0.4339\n",
      "Accuracy of KNN Model on Test: \n",
      " 0.4133\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logit 1 Model on Test: \\n', round(logit1.score(X_test2, y_test2),4))\n",
    "print('Accuracy of Decision Tree Model on Test: \\n', round(clf1.score(X_train2, y_train2),4))\n",
    "print('Accuracy of KNN Model on Test: \\n',round(knn.score(X_test2, y_test2),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logit 1 Model on Train: \n",
      " 0.4266\n",
      "Accuracy of Logit 1 Model on Validate: \n",
      " 0.4271\n",
      "Accuracy of Logit 1 Model on Test: \n",
      " 0.4235\n",
      "________________________________________________\n",
      "Accuracy of Decision Tree Model on Train: \n",
      " 0.4339\n",
      "Accuracy of Decision Tree Model on Validate: \n",
      " 0.4269\n",
      "Accuracy of Decision Tree Model on Test: \n",
      " 0.4339\n",
      "________________________________________________\n",
      "Accuracy of KNN Model on Train: \n",
      " 0.4696\n",
      "Accuracy of KNN Model on Validate: \n",
      " 0.4167\n",
      "Accuracy of KNN Model on Test: \n",
      " 0.4133\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logit 1 Model on Train: \\n', round(logit1.score(X_train2, y_train2),4))\n",
    "print('Accuracy of Logit 1 Model on Validate: \\n', round(logit1.score(X_validate2, y_validate2),4))\n",
    "print('Accuracy of Logit 1 Model on Test: \\n', round(logit1.score(X_test2, y_test2),4))\n",
    "print(\"________________________________________________\")\n",
    "print('Accuracy of Decision Tree Model on Train: \\n', round(clf1.score(X_train2, y_train2),4))\n",
    "print('Accuracy of Decision Tree Model on Validate: \\n', round(clf1.score(X_validate2, y_validate2),4))\n",
    "print('Accuracy of Decision Tree Model on Test: \\n', round(clf1.score(X_train2, y_train2),4))\n",
    "print(\"________________________________________________\")\n",
    "print('Accuracy of KNN Model on Train: \\n',round(knn.score(X_train2, y_train2),4))\n",
    "print('Accuracy of KNN Model on Validate: \\n',round(knn.score(X_validate2, y_validate2),4))\n",
    "print('Accuracy of KNN Model on Test: \\n',round(knn.score(X_test2, y_test2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
